{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write by  [Jianguo Zhang](https://github.com/JianguoZhang1994) , April 4, 2017\n",
    " Multiple Folders assign labels for acceleration data, 1 label is 1\n",
    "second, 1 second corresponds to 12 datas, each data includes 3 x, y, z\n",
    "\n",
    "Original data in **Baboon_Coding** folder and **output** folder. **Baboon_Coding** folder includes several xls files, **output** folder includes several acceleration dataset. Notices some xls files do not have corresponding acceleration data, you need to deal with carefully.\n",
    "\n",
    "Results in **Feeding** folder, **Interacting** folder and **Multiple_label** folder. For **Feeding**, where 1 represents feeding, 0 represents not feeding. For **Interacting folder**, where 1 represents interacting, 0 represents not interacting. For **Multiple_labels folder**, where 1 is running, 2 is walking, 3 is sitting, 4 is standing at rest, 5 is others. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "folder1='./Baboon_Coding/'\n",
    "filename1=[]\n",
    "full_path1=[]\n",
    "for filename in os.listdir(folder1):\n",
    "    filename1.append(filename)\n",
    "\n",
    "\"\"\"filename1: xlsfiles; filename2: matfiles\"\"\"    \n",
    "    \n",
    "folder2='./output/'\n",
    "filename2=[]\n",
    "full_path2=[]\n",
    "for filename in os.listdir(folder2):\n",
    "    filename2.append(filename)\n",
    "\n",
    "filename1=filename1[1:]\n",
    "for i in range(len(filename1)):\n",
    "    full_path1.append(folder1+filename1[i])\n",
    "\n",
    "for i in range(len(filename2)):\n",
    "    full_path2.append(folder2+filename2[i])\n",
    "\n",
    "full_path1[0]\n",
    "\n",
    "folder3='./Feeding/'\n",
    "folder4='./Interacting/'\n",
    "folder5='./Multiple_labels/'\n",
    "\n",
    "folder6='./Multiple_labels/'\n",
    "filename6=[]\n",
    "full_path6=[]\n",
    "for filename in os.listdir(folder6):\n",
    "    filename6.append(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import pandas as pd\n",
    "import math \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./output/0808_00001_2426_lau.mat'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_path2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0808_00000_2457_Lau'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename1[0][0:len(filename1[0])-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0808_00000_2457_lau'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename2[0][0:len(filename2[0])-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Feeding, Interacting, Multiple labels for all files, save in Feeding folder, Interacting folder and Multiple_labels folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0808_00000_2457_Lau\n",
      "4 119\n",
      "130 231\n",
      "239 309\n",
      "0808_00001_2426_Lau\n",
      "60 142\n",
      "0808_00001_2449_Lau\n",
      "5 56\n",
      "66 78\n",
      "0808_00002_2454_Lau\n",
      "3 18\n",
      "21 176\n",
      "180 213\n",
      "0808_00003_2427_Lau\n",
      "2 31\n",
      "0808_00007_2451_Lau\n",
      "0808_00008_2426_Lau\n",
      "2 49\n",
      "0808_00009_2427_Lau\n",
      "4 13\n",
      "0808_00010_2454_Lau\n",
      "98 169\n",
      "0808_00010_2457_Lau\n",
      "13 19\n",
      "72 101\n",
      "0810_00006_2427_Lau\n",
      "26 32\n",
      "38 215\n",
      "0810_00008_2427_Lau\n",
      "70 78\n",
      "88 192\n",
      "0810_00009_2427_Lau\n",
      "5 160\n",
      "0810_00012_2427_Lau\n",
      "109 128\n",
      "134 163\n",
      "0810_2426-034023_2426_Lau\n",
      "1 9\n",
      "0812_00005_2427_Lau\n",
      "1 83\n",
      "0812_00009_2449_Lau\n",
      "0812_00012_2436_Lau\n",
      "145 155\n",
      "0813_00018_2427_Lau\n",
      "14 58\n",
      "0813_00019_2428_Lau\n",
      "0813_00024_2446_Lau\n",
      "12 44\n",
      "64 65\n",
      "71 78\n",
      "0813_00025_2451_Lau\n",
      "0813_00026_2451_Lau\n",
      "0813_00026_2457_Lau\n",
      "0 33\n",
      "0813_00027_2451_Lau\n",
      "56 69\n",
      "0813_00027_2457_Lau\n",
      "0814_00000_2427_Lau\n",
      "6 151\n",
      "158 225\n",
      "227 240\n",
      "259 262\n",
      "266 369\n",
      "0814_00001_2426_Lau\n",
      "0814_00002_2427_Lau\n",
      "0814_00002_2451_Lau\n",
      "2 56\n",
      "185 192\n",
      "277 372\n",
      "0814_00002_2457_Lau\n",
      "5 59\n",
      "88 109\n",
      "159 165\n",
      "186 189\n",
      "220 229\n",
      "362 377\n",
      "0814_00003_2451_Lau\n",
      "0814_00003_2457_Lau\n",
      "0817_00001_2427_Lau\n",
      "1 46\n",
      "0817_00002_2426_Lau\n",
      "14 22\n",
      "27 54\n",
      "81 115\n",
      "0817_00002_2427_Lau\n",
      "0817_00003_2426_Lau\n",
      "69 228\n",
      "0817_00003_2443_Lau\n",
      "5 12\n",
      "28 144\n",
      "266 318\n",
      "0818_00007_2426_Lau\n",
      "13 32\n",
      "0818_00008_2451_Lau\n",
      "14 309\n",
      "319 360\n",
      "0818_00014_2426_Lau\n",
      "0 38\n",
      "42 150\n",
      "154 166\n",
      "0827_00000_2426_Lau\n",
      "0827_00001_2426_Lau\n",
      "0827_00005_2426_Lau\n",
      "4 29\n",
      "31 357\n",
      "377 479\n",
      "494 504\n",
      "525 641\n",
      "720 728\n",
      "739 832\n",
      "0827_00005_2451_Lau\n",
      "152 359\n",
      "370 581\n",
      "630 639\n",
      "642 677\n",
      "0827_00005_2457_Lau\n",
      "92 671\n",
      "695 832\n",
      "0827_00007_2427_Lau\n",
      "13 125\n",
      "135 194\n",
      "0827_00008_2447_Lau\n",
      "0827_00010_2447_Lau\n",
      "0827_00012_2451_Lau\n",
      "0827_00012_2457_Lau\n",
      "0828_00013_2426_Lau\n",
      "3 68\n",
      "442 521\n",
      "527 529\n",
      "0828_00013_2427_Lau\n",
      "323 385\n",
      "391 440\n",
      "552 625\n",
      "0828_00013_2451_Lau\n",
      "20 40\n",
      "74 80\n",
      "126 431\n",
      "0828_00013_2457_Lau\n",
      "19 26\n",
      "80 438\n",
      "441 625\n",
      "0828_00014_2426_Lau\n",
      "140 206\n",
      "0828_00014_2427_Lau\n",
      "55 297\n",
      "0828_00014_2457_Lau\n",
      "84 109\n",
      "0828_00015_2426_Lau\n",
      "10 53\n",
      "149 201\n",
      "0828_00015_2447_Lau\n",
      "0828_00018_2427_Lau\n",
      "0828_00020_2426_Lau\n",
      "3 15\n",
      "51 128\n",
      "141 191\n",
      "0829_00000_2457_Lau\n",
      "8 182\n",
      "190 395\n",
      "401 444\n",
      "0829_00001_2427_Lau\n",
      "4 93\n",
      "109 178\n",
      "0829_00002_2457_Lau\n",
      "1 5\n",
      "24 45\n",
      "51 121\n",
      "0830_00003_2427_Lau\n",
      "3 29\n",
      "32 1018\n",
      "0830_00004_2427_Lau\n",
      "7 280\n",
      "315 646\n",
      "0830_00005_2451_Lau\n",
      "53 79\n",
      "83 94\n",
      "103 212\n",
      "215 356\n",
      "0830_00005_2457_Lau\n",
      "3 6\n",
      "17 52\n",
      "164 248\n",
      "0830_00006_2457_Lau\n",
      "2 111\n",
      "0830_00007_2451_Lau\n",
      "216 397\n",
      "0830_00009_2457_Lau\n",
      "11 265\n",
      "0830_00012_2427_Lau\n",
      "0830_00013_2457_Lau\n",
      "2 90\n",
      "0830_00014_2457_Lau\n",
      "6 84\n",
      "94 141\n",
      "159 168\n",
      "175 180\n",
      "188 250\n",
      "320 365\n",
      "0831_00014_2451_Lau\n",
      "107 141\n",
      "0831_00015_2427_Lau\n",
      "51 126\n",
      "139 259\n",
      "0831_00016_2451_Lau\n",
      "9 47\n",
      "52 107\n",
      "112 178\n",
      "0831_00017_2427_Lau\n",
      "87 108\n",
      "113 142\n",
      "0831_00017_2457_Lau\n",
      "2 22\n",
      "22 82\n",
      "95 110\n",
      "151 159\n",
      "162 215\n",
      "0831_00018_2457_Lau\n",
      "61 88\n",
      "0831_00019_2427_Lau\n",
      "0831_00020_2457_Lau\n",
      "10 19\n",
      "0831_00021_2443_Lau\n",
      "3 108\n",
      "0831_00023_2443_Lau\n",
      "0831_00024_2443_Lau\n",
      "0831_00025_2443_Lau\n",
      "0831_00026_2427_Lau\n",
      "0831_00027_2443_Lau\n",
      "0831_00028_2457_Lau\n"
     ]
    }
   ],
   "source": [
    "#Read data\n",
    "for iteration in range(len(full_path1)): \n",
    "   \n",
    "    #get 0808_00000_2457_Lau\n",
    "    attribute_file=filename1[iteration][0:len(filename1[iteration])-4]\n",
    "    f=False\n",
    "    for index in range(len(filename2)):\n",
    "        if attribute_file.lower()==filename2[index][0:len(filename2[index])-4].lower():\n",
    "            f=True\n",
    "    if(f==False):\n",
    "        continue\n",
    "\n",
    "\n",
    "    #dataFile=full_path2[iteration]\n",
    "    dataFile=folder2+attribute_file+'.mat'\n",
    "    #dataFile = './output/0808_00000_2457_Lau.mat'\n",
    "    data = scio.loadmat(dataFile)\n",
    "    acc_data_x=data['acc_data_x'][0]\n",
    "    acc_data_y=data['acc_data_y'][0]\n",
    "    acc_data_z=data['acc_data_z'][0]\n",
    "    N=len(acc_data_x)\n",
    "    \n",
    "    \n",
    "    xls_path=full_path1[iteration]\n",
    "    xlsFile=pd.read_excel(xls_path)\n",
    "    \n",
    "    time=[]\n",
    "    subject=[]\n",
    "    behavior=[]\n",
    "    status=[]\n",
    "    df=[]\n",
    "    \n",
    "   \n",
    "    print(attribute_file)\n",
    "    \n",
    "    \n",
    "    df_time=xlsFile['Observation id']\n",
    "    df_subject=xlsFile[attribute_file]\n",
    "    df_behavior=xlsFile['Unnamed: 2']\n",
    "    df_status=xlsFile['Unnamed: 4']\n",
    "\n",
    "    for ii in range(len(df_time)):\n",
    "        if(df_time[ii]=='Time'):\n",
    "            break\n",
    "\n",
    "    #Remove 'feeding', 'Out of Frame', 'Interacting'        \n",
    "    for j in range(ii+1, len(df_time)):\n",
    "        #if(df_behavior[i+1:][j] not in('Feeding', 'Out of Frame', 'Interacting')):\n",
    "        df.append([float(df_time[j]), df_subject[ii+1:][j], df_behavior[ii+1:][j], df_status[ii+1:][j]])\n",
    "        time.append(float(df_time[j]))\n",
    "        subject.append(df_subject[ii+1:][j])\n",
    "        behavior.append(df_behavior[ii+1:][j])\n",
    "        status.append(df_status[ii+1:][j])\n",
    "    \"\"\"get df\"\"\"\n",
    "    \n",
    "    ##***********Feeding or not*****************\n",
    "    labels_feeding=np.zeros(N)\n",
    "    \n",
    "    flag=False\n",
    "    for i in range(len(df)):\n",
    "        if(behavior[i]==\"Feeding\" and status[i]==\"START\"): \n",
    "            a=math.floor(time[i])\n",
    "    #         if(a>int(N/12)):\n",
    "    #             break\n",
    "            flag=False\n",
    "            if(a+1-time[i]>=0.5):\n",
    "                labels_feeding[a]=1\n",
    "            else:\n",
    "                labels_feeding[a]=0\n",
    "        elif(behavior[i]==\"Feeding\" and status[i]==\"STOP\"):\n",
    "            b=math.floor(time[i])\n",
    "    #         if(b>int(N/12)):\n",
    "    #             break\n",
    "            flag=True\n",
    "            if(time[i]-b>=0.5):\n",
    "                labels_feeding[b]=1\n",
    "            else:\n",
    "                labels_feeding[b]=0\n",
    "        if(flag):\n",
    "            print(a, b)\n",
    "\n",
    "            for j in range(a+1, b):\n",
    "                labels_feeding[j]=1\n",
    "            flag=False\n",
    "    if(a>b):\n",
    "        for i in range(a+1, N):\n",
    "            labels_feeding[i]=1\n",
    "\n",
    "\n",
    "    labels_feeding=labels_feeding[0:int(N/12)]\n",
    "\n",
    "\n",
    "    np.savetxt(folder3+attribute_file+'.csv', labels_feeding, fmt='%d', header='Feeding')    \n",
    "\n",
    "    ###****************Interacting or not******************\n",
    "    labels_Interacting=np.zeros(N)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if(behavior[i]==\"Interacting\" and status[i]==\"POINT\"): \n",
    "            a=math.floor(time[i])\n",
    "            labels_Interacting[a]=1\n",
    "\n",
    "    labels_Interacting=labels_Interacting[0:int(N/12)]\n",
    "\n",
    "\n",
    "    np.savetxt(folder4+attribute_file+'.csv', labels_Interacting, fmt='%d', header='Interacting')    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ###****************Multiple behaviors******************\n",
    "    labels_multiple=np.ones(N)*5\n",
    "\n",
    "    flag1=False\n",
    "    flag2=False\n",
    "    flag3=False\n",
    "    flag4=False\n",
    "    for i in range(len(df)):\n",
    "        #Running\n",
    "        if(behavior[i]==\"Running\" and status[i]==\"START\"): \n",
    "            a1=math.floor(time[i])\n",
    "            flag1=False\n",
    "            if(a1+1-time[i]>=0.5):\n",
    "                labels_multiple[a1]=1       \n",
    "        elif(behavior[i]==\"Running\" and status[i]==\"STOP\"):\n",
    "            b1=math.floor(time[i])\n",
    "            flag1=True\n",
    "            if(time[i]-b1>=0.5):\n",
    "                labels_multiple[b1]=1 \n",
    "\n",
    "        #Walking\n",
    "        if(behavior[i]==\"Walking\" and status[i]==\"START\"): \n",
    "            a2=math.floor(time[i])\n",
    "            flag2=False\n",
    "            if(a2+1-time[i]>=0.5):\n",
    "                labels_multiple[a2]=2\n",
    "        elif(behavior[i]==\"Walking\" and status[i]==\"STOP\"):\n",
    "            b2=math.floor(time[i])\n",
    "            flag2=True\n",
    "            if(time[i]-b2>=0.5):\n",
    "                labels_multiple[b2]=2\n",
    "\n",
    "        #Sitting\n",
    "        if(behavior[i]==\"Sitting\" and status[i]==\"START\"): \n",
    "            a3=math.floor(time[i])\n",
    "            flag3=False\n",
    "            if(a3+1-time[i]>=0.5):\n",
    "                labels_multiple[a3]=3\n",
    "        elif(behavior[i]==\"Sitting\" and status[i]==\"STOP\"):\n",
    "            b3=math.floor(time[i])\n",
    "            flag3=True\n",
    "            if(time[i]-b3>=0.5):\n",
    "                labels_multiple[b3]=3\n",
    "\n",
    "        #Standing at rest\n",
    "        if(behavior[i]==\"Standing at rest\" and status[i]==\"START\"): \n",
    "            a4=math.floor(time[i])\n",
    "            flag4=False\n",
    "            if(a4+1-time[i]>=0.5):\n",
    "                labels_multiple[a4]=4     \n",
    "        elif(behavior[i]==\"Standing at rest\" and status[i]==\"STOP\"):\n",
    "            b4=math.floor(time[i])\n",
    "            flag4=True\n",
    "            if(time[i]-b4>=0.5):\n",
    "                 labels_multiple[b4]=4\n",
    "\n",
    "        if(flag1):\n",
    "            for j in range(a1+1, b1):\n",
    "                labels_multiple[j]=1\n",
    "            flag1=False\n",
    "        elif(flag2):\n",
    "            for j in range(a2+1, b2):\n",
    "                labels_multiple[j]=2\n",
    "            flag2=False\n",
    "        elif(flag3):\n",
    "            for j in range(a3+1, b3):\n",
    "                labels_multiple[j]=3\n",
    "            flag3=False\n",
    "        elif(flag4):\n",
    "            for j in range(a4+1, b4):\n",
    "                labels_multiple[j]=4\n",
    "            flag4=False\n",
    "    \n",
    "    if(a1>b1):\n",
    "        for i in range(a1+1, N):\n",
    "            labels_multiple[i]=1\n",
    "    elif(a2>b2):\n",
    "        for i in range(a2+1, N):\n",
    "            labels_multiple[i]=2\n",
    "    elif(a3>b3):\n",
    "        for i in range(a3+1, N):\n",
    "            labels_multiple[i]=3\n",
    "    elif(a4>b4):\n",
    "        for i in range(a4+1, N):\n",
    "            labels_multiple[i]=4\n",
    "    \n",
    "    labels_multiple=labels_multiple[0:int(N/12)]\n",
    "\n",
    "    \n",
    "    np.savetxt(folder5+attribute_file+'.csv', labels_multiple, fmt='%d', header='Multiple')    \n",
    "\n",
    "    \n",
    "#     dataFile=full_path1[i]\n",
    "#     #dataFile = './output/0808_00000_2457_Lau.mat'\n",
    "#     data = scio.loadmat(dataFile)\n",
    "#     acc_data_x=data['acc_data_x'][0]\n",
    "#     acc_data_y=data['acc_data_y'][0]\n",
    "#     acc_data_z=data['acc_data_z'][0]\n",
    "#     N=len(acc_data_x)\n",
    "#     print('dataFile %s. \\nSize of acc_data_x: %d'%(dataFile, len(acc_data_x)))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feeding or not(Do not run this cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 119\n",
      "130 231\n",
      "239 309\n"
     ]
    }
   ],
   "source": [
    "labels_feeding=np.zeros(N)\n",
    "i=1\n",
    "flag=False\n",
    "for i in range(len(df)):\n",
    "    if(behavior[i]==\"Feeding\" and status[i]==\"START\"): \n",
    "        a=math.floor(time[i])\n",
    "#         if(a>int(N/12)):\n",
    "#             break\n",
    "        flag=False\n",
    "        if(a+1-time[i]>=0.5):\n",
    "            labels_feeding[a]=1\n",
    "        else:\n",
    "            labels_feeding[a]=0\n",
    "    elif(behavior[i]==\"Feeding\" and status[i]==\"STOP\"):\n",
    "        b=math.floor(time[i])\n",
    "#         if(b>int(N/12)):\n",
    "#             break\n",
    "        flag=True\n",
    "        if(time[i]-b>=0.5):\n",
    "            labels_feeding[b]=1\n",
    "        else:\n",
    "            labels_feeding[b]=0\n",
    "    if(flag):\n",
    "        print(a, b)\n",
    "        \n",
    "        for j in range(a+1, b):\n",
    "            labels_feeding[j]=1\n",
    "        flag=False\n",
    "if(a>b):\n",
    "    for i in range(a+1, N):\n",
    "        labels_feeding[i]=1\n",
    "    \n",
    "\n",
    "labels_feeding=labels_feeding[0:int(N/12)]\n",
    "\n",
    "\n",
    "np.savetxt('./Label_Feeding/0808_00000_2457_Lau(2).csv', labels_feeding, fmt='%d')    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_file=pd.read_csv(folder5+'0808_00000_2457_Lau'+'.csv')\n",
    "label_file['# Multiple'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folder6='./Multiple_labels/'\n",
    "filename6=[]\n",
    "full_path6=[]\n",
    "for filename in os.listdir(folder6):\n",
    "    filename6.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142.0 142\n",
      "142.0 142\n",
      "213.0 213\n",
      "41.0 41\n",
      "41.0 41\n",
      "53.0 53\n",
      "33.0 33\n",
      "283.0 283\n",
      "283.0 283\n",
      "269.0 269\n",
      "234.0 234\n",
      "161.0 161\n",
      "269.0 269\n",
      "60.0 60\n",
      "148.0 148\n",
      "209.0 209\n",
      "532.0 532\n",
      "64.0 64\n",
      "20.0 20\n",
      "95.0 95\n",
      "36.0 36\n",
      "69.0 69\n",
      "69.0 69\n",
      "119.0 119\n",
      "119.0 119\n",
      "402.0 402\n",
      "21.0 21\n",
      "396.0 396\n",
      "396.0 396\n",
      "396.0 396\n",
      "938.0 938\n",
      "938.0 938\n",
      "52.0 52\n",
      "234.0 234\n",
      "234.0 234\n",
      "330.0 330\n",
      "330.0 330\n",
      "84.0 84\n",
      "538.0 538\n",
      "174.0 174\n",
      "65.0 65\n",
      "114.0 114\n",
      "832.0 832\n",
      "832.0 832\n",
      "832.0 832\n",
      "196.0 196\n",
      "56.0 56\n",
      "292.0 292\n",
      "1201.0 1201\n",
      "1201.0 1201\n",
      "625.0 625\n",
      "625.0 625\n",
      "625.0 625\n",
      "625.0 625\n",
      "297.0 297\n",
      "297.0 297\n",
      "297.0 297\n",
      "201.0 201\n",
      "207.0 207\n",
      "552.0 552\n",
      "276.0 276\n",
      "446.0 446\n",
      "183.0 183\n",
      "123.0 123\n",
      "1034.0 1034\n",
      "656.0 656\n",
      "656.0 656\n",
      "656.0 656\n",
      "111.0 111\n",
      "399.0 399\n",
      "265.0 265\n",
      "67.0 67\n",
      "153.0 153\n",
      "383.0 383\n",
      "383.0 383\n",
      "290.0 290\n",
      "180.0 180\n",
      "215.0 215\n",
      "215.0 215\n",
      "104.0 104\n",
      "31.0 31\n",
      "137.0 137\n",
      "782.0 782\n",
      "169.0 169\n",
      "492.0 492\n",
      "74.0 74\n",
      "215.0 215\n",
      "196.0 196\n",
      "167.0 167\n",
      "28505 28505\n"
     ]
    }
   ],
   "source": [
    "#Read data\n",
    "import scipy.io as scio\n",
    "import pandas as pd\n",
    "\n",
    "# dataFile = './output/0808_00000_2457_Lau.mat'\n",
    "# data = scio.loadmat(dataFile)\n",
    "# acc_data_x=data['acc_data_x'][0]\n",
    "# acc_data_y=data['acc_data_y'][0]\n",
    "# acc_data_z=data['acc_data_z'][0]\n",
    "# N=len(acc_data_x)\n",
    "# print('dataFile %s. \\nSize of acc_data_x: %d'%(dataFile, len(acc_data_x)))\n",
    "\n",
    "\n",
    "total_label=[]\n",
    "\n",
    "#dataFile=full_path2[iteration]\n",
    "attribute_file=filename6[0][0:len(filename6[0])-4]\n",
    "dataFile=folder2+attribute_file+'.mat'\n",
    "#print(dataFile)\n",
    "#dataFile = './output/0808_00000_2457_Lau.mat'\n",
    "data = scio.loadmat(dataFile)\n",
    "acc_data_x=data['acc_data_x'][0]\n",
    "acc_data_y=data['acc_data_y'][0]\n",
    "acc_data_z=data['acc_data_z'][0]\n",
    "\n",
    "NaN_number=[]\n",
    "for j in range(len(acc_data_x)):\n",
    "    if(math.isnan(acc_data_x[j]) or math.isnan(acc_data_y[j]) or math.isnan(acc_data_z[j])\\\n",
    "      or math.isinf(acc_data_x[j]) or math.isinf(acc_data_y[j]) or math.isinf(acc_data_z[j])):\n",
    "        NaN_number.append(math.floor(j/12))\n",
    "#print(NaN_number)\n",
    "total_data=[acc_data_x, acc_data_y, acc_data_z]\n",
    "\n",
    "label_file=pd.read_csv(folder6+attribute_file+'.csv')\n",
    "for i in range(len(label_file['# Multiple'])):\n",
    "    if(i in NaN_number): \n",
    "        total_label.append(5)\n",
    "        continue\n",
    "    total_label.append(label_file['# Multiple'][i])\n",
    "    \n",
    "\n",
    "for iteration in range(1,len(filename6)):\n",
    "    attribute_file=filename6[iteration][0:len(filename6[iteration])-4]\n",
    "    f=False\n",
    "    for index in range(len(filename2)):\n",
    "        if attribute_file.lower()==filename2[index][0:len(filename2[index])-4].lower():\n",
    "            f=True\n",
    "        if(f==False):\n",
    "            continue\n",
    "\n",
    "    #dataFile=full_path2[iteration]\n",
    "    dataFile=folder2+attribute_file+'.mat'\n",
    "    #dataFile = './output/0808_00000_2457_Lau.mat'\n",
    "    data = scio.loadmat(dataFile)\n",
    "    acc_data_x=data['acc_data_x'][0]\n",
    "    acc_data_y=data['acc_data_y'][0]\n",
    "    acc_data_z=data['acc_data_z'][0]\n",
    "    \n",
    "    NaN_number=[] #\n",
    "    for j in range(len(acc_data_x)):\n",
    "        if(math.isnan(acc_data_x[j]) or math.isnan(acc_data_y[j]) or math.isnan(acc_data_z[j])\\\n",
    "      or math.isinf(acc_data_x[j]) or math.isinf(acc_data_y[j]) or math.isinf(acc_data_z[j])):\n",
    "            NaN_number.append(math.floor(j/12))\n",
    "    # print(NaN_number)  \n",
    "    a=[acc_data_x, acc_data_y, acc_data_z]\n",
    "    total_data=np.concatenate((total_data, a), axis=1)\n",
    "    \n",
    "    label_file=pd.read_csv(folder6+attribute_file+'.csv')\n",
    "    aa=[]\n",
    "    for i in range(len(label_file['# Multiple'])):\n",
    "        if(i in NaN_number): \n",
    "            aa.append(5)\n",
    "            total_label.append(5)\n",
    "            continue\n",
    "        aa.append(label_file['# Multiple'][i])\n",
    "        total_label.append(label_file['# Multiple'][i])\n",
    "\n",
    "    print(len(a[0])/12, len(aa))\n",
    "\n",
    "\n",
    "c=[]\n",
    "for i in range(0,len(total_data[0]), 12):\n",
    "    c.append(np.array([total_data[0][i:i+12], total_data[1][i:i+12], total_data[2][i:i+12]]))\n",
    "\n",
    "d=[]\n",
    "# c=d[0].reshape(1,36)\n",
    "for i in range(len(c)):\n",
    "    d.append(c[i].reshape(1, 36))\n",
    "    d[i]=d[i][0]\n",
    "\n",
    "dataset=d\n",
    "\n",
    "print(len(dataset), len(total_label))      \n",
    "        \n",
    "\n",
    "# a=[];\n",
    "# acc_x=np.zeros(N)\n",
    "# acc_y=np.zeros(N)\n",
    "# acc_z=np.zeros(N)\n",
    "# for i in range(N):\n",
    "#     acc_x[i]=int(acc_data_x[i])\n",
    "#     acc_y[i]=int(acc_data_y[i])\n",
    "#     acc_z[i]=int(acc_data_z[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1884.,  1950.,  1898.,  1945.,  1954.,  2020.,  1942.,  2004.,\n",
       "        1904.,  1984.,  1911.,  1943.,  2163.,  2280.,  2321.,  2300.,\n",
       "        2286.,  2427.,  2260.,  2261.,  2330.,  2220.,  2214.,  2197.,\n",
       "        2320.,  2287.,  2324.,  2242.,  2260.,  2272.,  2216.,  2268.,\n",
       "        2339.,  2330.,  2280.,  2248.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_dataset=[]\n",
    "new_labels_multiple=[]\n",
    "for i in range(len(dataset)):\n",
    "    if(total_label[i]==5):\n",
    "        continue\n",
    "    new_dataset.append(dataset[i])\n",
    "    new_labels_multiple.append(total_label[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20348 20348\n"
     ]
    }
   ],
   "source": [
    "print(len(new_dataset), len(new_labels_multiple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "clf = clf.fit(, Y)\n",
    "\n",
    "A=clf.predict(X_test)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All labels confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79083665,  0.79241517,  0.794     ,  0.794     ,  0.794     ,\n",
       "        0.794     ,  0.794     ,  0.79559118,  0.79559118,  0.79559118])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='rbf', C=1)\n",
    "scores = cross_val_score(clf, new_dataset[10000:15000], new_labels_multiple[10000:15000], cv=10)\n",
    "\n",
    "scores\n",
    "# clf = svm.SVC(kernel='Linear', C=1).fit(X_train, y_train)\n",
    "# clf.score(X_test, y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For train_test and build confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     new_dataset, new_labels_multiple, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='rbf', C=1).fit(X_train, y_train)\n",
    "y_predict=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    1,   49,    0],\n",
       "       [   0,    2,  989,    0],\n",
       "       [   1,    6, 4362,    8],\n",
       "       [   0,    0,  687,    0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(y_test, y_predict, labels=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional methons(do not run this cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "#n_samples = dataset.shape[0]\n",
    "clf = svm.SVC(kernel='rbf', C=1)\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "scores2=cross_val_score(clf, new_dataset, new_labels_multiple, cv=cv)\n",
    "scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.63 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feeding or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder6='./Feeding/'\n",
    "filename6=[]\n",
    "full_path6=[]\n",
    "for filename in os.listdir(folder6):\n",
    "    filename6.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142.0 142\n",
      "142.0 142\n",
      "213.0 213\n",
      "41.0 41\n",
      "41.0 41\n",
      "53.0 53\n",
      "33.0 33\n",
      "283.0 283\n",
      "283.0 283\n",
      "269.0 269\n",
      "234.0 234\n",
      "161.0 161\n",
      "269.0 269\n",
      "60.0 60\n",
      "148.0 148\n",
      "209.0 209\n",
      "532.0 532\n",
      "64.0 64\n",
      "20.0 20\n",
      "95.0 95\n",
      "36.0 36\n",
      "69.0 69\n",
      "69.0 69\n",
      "119.0 119\n",
      "119.0 119\n",
      "402.0 402\n",
      "21.0 21\n",
      "396.0 396\n",
      "396.0 396\n",
      "396.0 396\n",
      "938.0 938\n",
      "938.0 938\n",
      "52.0 52\n",
      "234.0 234\n",
      "234.0 234\n",
      "330.0 330\n",
      "330.0 330\n",
      "84.0 84\n",
      "538.0 538\n",
      "174.0 174\n",
      "65.0 65\n",
      "114.0 114\n",
      "832.0 832\n",
      "832.0 832\n",
      "832.0 832\n",
      "196.0 196\n",
      "56.0 56\n",
      "292.0 292\n",
      "1201.0 1201\n",
      "1201.0 1201\n",
      "625.0 625\n",
      "625.0 625\n",
      "625.0 625\n",
      "625.0 625\n",
      "297.0 297\n",
      "297.0 297\n",
      "297.0 297\n",
      "201.0 201\n",
      "207.0 207\n",
      "552.0 552\n",
      "276.0 276\n",
      "446.0 446\n",
      "183.0 183\n",
      "123.0 123\n",
      "1034.0 1034\n",
      "656.0 656\n",
      "656.0 656\n",
      "656.0 656\n",
      "111.0 111\n",
      "399.0 399\n",
      "265.0 265\n",
      "67.0 67\n",
      "153.0 153\n",
      "383.0 383\n",
      "383.0 383\n",
      "290.0 290\n",
      "180.0 180\n",
      "215.0 215\n",
      "215.0 215\n",
      "104.0 104\n",
      "31.0 31\n",
      "137.0 137\n",
      "782.0 782\n",
      "169.0 169\n",
      "492.0 492\n",
      "74.0 74\n",
      "215.0 215\n",
      "196.0 196\n",
      "167.0 167\n",
      "28505 28505\n"
     ]
    }
   ],
   "source": [
    "#Read data\n",
    "import scipy.io as scio\n",
    "import pandas as pd\n",
    "\n",
    "# dataFile = './output/0808_00000_2457_Lau.mat'\n",
    "# data = scio.loadmat(dataFile)\n",
    "# acc_data_x=data['acc_data_x'][0]\n",
    "# acc_data_y=data['acc_data_y'][0]\n",
    "# acc_data_z=data['acc_data_z'][0]\n",
    "# N=len(acc_data_x)\n",
    "# print('dataFile %s. \\nSize of acc_data_x: %d'%(dataFile, len(acc_data_x)))\n",
    "\n",
    "\n",
    "total_label=[]\n",
    "\n",
    "#dataFile=full_path2[iteration]\n",
    "attribute_file=filename6[0][0:len(filename6[0])-4]\n",
    "dataFile=folder2+attribute_file+'.mat'\n",
    "#print(dataFile)\n",
    "#dataFile = './output/0808_00000_2457_Lau.mat'\n",
    "data = scio.loadmat(dataFile)\n",
    "acc_data_x=data['acc_data_x'][0]\n",
    "acc_data_y=data['acc_data_y'][0]\n",
    "acc_data_z=data['acc_data_z'][0]\n",
    "\n",
    "NaN_number=[]\n",
    "for j in range(len(acc_data_x)):\n",
    "    if(math.isnan(acc_data_x[j]) or math.isnan(acc_data_y[j]) or math.isnan(acc_data_z[j])\\\n",
    "      or math.isinf(acc_data_x[j]) or math.isinf(acc_data_y[j]) or math.isinf(acc_data_z[j])):\n",
    "        NaN_number.append(math.floor(j/12))\n",
    "#print(NaN_number)\n",
    "total_data=[acc_data_x, acc_data_y, acc_data_z]\n",
    "\n",
    "label_file=pd.read_csv(folder6+attribute_file+'.csv')\n",
    "for i in range(len(label_file['# Feeding'])):\n",
    "    if(i in NaN_number): \n",
    "        total_label.append(5)\n",
    "        continue\n",
    "    total_label.append(label_file['# Feeding'][i])\n",
    "    \n",
    "\n",
    "for iteration in range(1,len(filename6)):\n",
    "    attribute_file=filename6[iteration][0:len(filename6[iteration])-4]\n",
    "    f=False\n",
    "    for index in range(len(filename2)):\n",
    "        if attribute_file.lower()==filename2[index][0:len(filename2[index])-4].lower():\n",
    "            f=True\n",
    "        if(f==False):\n",
    "            continue\n",
    "\n",
    "    #dataFile=full_path2[iteration]\n",
    "    dataFile=folder2+attribute_file+'.mat'\n",
    "    #dataFile = './output/0808_00000_2457_Lau.mat'\n",
    "    data = scio.loadmat(dataFile)\n",
    "    acc_data_x=data['acc_data_x'][0]\n",
    "    acc_data_y=data['acc_data_y'][0]\n",
    "    acc_data_z=data['acc_data_z'][0]\n",
    "    \n",
    "    NaN_number=[] #\n",
    "    for j in range(len(acc_data_x)):\n",
    "        if(math.isnan(acc_data_x[j]) or math.isnan(acc_data_y[j]) or math.isnan(acc_data_z[j])\\\n",
    "      or math.isinf(acc_data_x[j]) or math.isinf(acc_data_y[j]) or math.isinf(acc_data_z[j])):\n",
    "            NaN_number.append(math.floor(j/12))\n",
    "    # print(NaN_number)  \n",
    "    a=[acc_data_x, acc_data_y, acc_data_z]\n",
    "    total_data=np.concatenate((total_data, a), axis=1)\n",
    "    \n",
    "    label_file=pd.read_csv(folder6+attribute_file+'.csv')\n",
    "    aa=[]\n",
    "    for i in range(len(label_file['# Feeding'])):\n",
    "        if(i in NaN_number): \n",
    "            aa.append(5)\n",
    "            total_label.append(5)\n",
    "            continue\n",
    "        aa.append(label_file['# Feeding'][i])\n",
    "        total_label.append(label_file['# Feeding'][i])\n",
    "\n",
    "    print(len(a[0])/12, len(aa))\n",
    "\n",
    "\n",
    "c=[]\n",
    "for i in range(0,len(total_data[0]), 12):\n",
    "    c.append(np.array([total_data[0][i:i+12], total_data[1][i:i+12], total_data[2][i:i+12]]))\n",
    "\n",
    "d=[]\n",
    "# c=d[0].reshape(1,36)\n",
    "for i in range(len(c)):\n",
    "    d.append(c[i].reshape(1, 36))\n",
    "    d[i]=d[i][0]\n",
    "\n",
    "dataset=d\n",
    "\n",
    "print(len(dataset), len(total_label))      \n",
    "        \n",
    "\n",
    "# a=[];\n",
    "# acc_x=np.zeros(N)\n",
    "# acc_y=np.zeros(N)\n",
    "# acc_z=np.zeros(N)\n",
    "# for i in range(N):\n",
    "#     acc_x[i]=int(acc_data_x[i])\n",
    "#     acc_y[i]=int(acc_data_y[i])\n",
    "#     acc_z[i]=int(acc_data_z[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_dataset=[]\n",
    "new_labels_multiple=[]\n",
    "for i in range(len(dataset)):\n",
    "    if(total_label[i]==5):\n",
    "        continue\n",
    "    new_dataset.append(dataset[i])\n",
    "    new_labels_multiple.append(total_label[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.57361163,  0.58762118,  0.59567326,  0.58373741,  0.58784036,\n",
       "        0.58784036,  0.58784036,  0.54755688,  0.58784036,  0.58784036])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='rbf', C=1)\n",
    "scores = cross_val_score(clf, new_dataset, new_labels_multiple, cv=10)\n",
    "\n",
    "scores\n",
    "# clf = svm.SVC(kernel='Linear', C=1).fit(X_train, y_train)\n",
    "# clf.score(X_test, y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.58 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Multiple features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folder6='./Feeding/'\n",
    "filename6=[]\n",
    "full_path6=[]\n",
    "for filename in os.listdir(folder6):\n",
    "    filename6.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from astropy.stats import median_absolute_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142.0 142\n",
      "142.0 142\n",
      "213.0 213\n",
      "41.0 41\n",
      "41.0 41\n",
      "53.0 53\n",
      "33.0 33\n",
      "283.0 283\n",
      "283.0 283\n",
      "269.0 269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.6/site-packages/numpy/lib/function_base.py:3858: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "//anaconda/lib/python3.6/site-packages/numpy/lib/function_base.py:4116: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1808 1808\n"
     ]
    }
   ],
   "source": [
    "#Read data\n",
    "import scipy.io as scio\n",
    "import pandas as pd\n",
    "\n",
    "# dataFile = './output/0808_00000_2457_Lau.mat'\n",
    "# data = scio.loadmat(dataFile)\n",
    "# acc_data_x=data['acc_data_x'][0]\n",
    "# acc_data_y=data['acc_data_y'][0]\n",
    "# acc_data_z=data['acc_data_z'][0]\n",
    "# N=len(acc_data_x)\n",
    "# print('dataFile %s. \\nSize of acc_data_x: %d'%(dataFile, len(acc_data_x)))\n",
    "\n",
    "\n",
    "total_label=[]\n",
    "\n",
    "#dataFile=full_path2[iteration]\n",
    "attribute_file=filename6[0][0:len(filename6[0])-4]\n",
    "dataFile=folder2+attribute_file+'.mat'\n",
    "#print(dataFile)\n",
    "#dataFile = './output/0808_00000_2457_Lau.mat'\n",
    "data = scio.loadmat(dataFile)\n",
    "acc_data_x=data['acc_data_x'][0]\n",
    "acc_data_y=data['acc_data_y'][0]\n",
    "acc_data_z=data['acc_data_z'][0]\n",
    "\n",
    "NaN_number=[]\n",
    "for j in range(len(acc_data_x)):\n",
    "    if(math.isnan(acc_data_x[j]) or math.isnan(acc_data_y[j]) or math.isnan(acc_data_z[j])\\\n",
    "      or math.isinf(acc_data_x[j]) or math.isinf(acc_data_y[j]) or math.isinf(acc_data_z[j])):\n",
    "        NaN_number.append(math.floor(j/12))\n",
    "#print(NaN_number)\n",
    "total_data=[acc_data_x, acc_data_y, acc_data_z]\n",
    "\n",
    "label_file=pd.read_csv(folder6+attribute_file.lower()+'.csv')\n",
    "for i in range(len(label_file['# Feeding'])):\n",
    "    if(i in NaN_number): \n",
    "        total_label.append(5)\n",
    "        continue\n",
    "    total_label.append(label_file['# Feeding'][i])\n",
    "    \n",
    "\n",
    "for iteration in range(1,11):\n",
    "    attribute_file=filename6[iteration][0:len(filename6[iteration])-4]\n",
    "    f=False\n",
    "    for index in range(len(filename2)):\n",
    "        if attribute_file.lower()==filename2[index][0:len(filename2[index])-4].lower():\n",
    "            f=True\n",
    "    if(f==False):\n",
    "        continue\n",
    "\n",
    "    #dataFile=full_path2[iteration]\n",
    "    dataFile=folder2+attribute_file+'.mat'\n",
    "    #dataFile = './output/0808_00000_2457_Lau.mat'\n",
    "    data = scio.loadmat(dataFile)\n",
    "    acc_data_x=data['acc_data_x'][0]\n",
    "    acc_data_y=data['acc_data_y'][0]\n",
    "    acc_data_z=data['acc_data_z'][0]\n",
    "    \n",
    "    NaN_number=[] #\n",
    "    for j in range(len(acc_data_x)):\n",
    "        if(math.isnan(acc_data_x[j]) or math.isnan(acc_data_y[j]) or math.isnan(acc_data_z[j])\\\n",
    "      or math.isinf(acc_data_x[j]) or math.isinf(acc_data_y[j]) or math.isinf(acc_data_z[j])):\n",
    "            NaN_number.append(math.floor(j/12))\n",
    "    # print(NaN_number)  \n",
    "    a=[acc_data_x, acc_data_y, acc_data_z]\n",
    "    total_data=np.concatenate((total_data, a), axis=1)\n",
    "    \n",
    "    label_file=pd.read_csv(folder6+attribute_file.lower()+'.csv')\n",
    "    aa=[]\n",
    "    for i in range(len(label_file['# Feeding'])):\n",
    "        if(i in NaN_number): \n",
    "            aa.append(5)\n",
    "            total_label.append(5)\n",
    "            continue\n",
    "        aa.append(label_file['# Feeding'][i])\n",
    "        total_label.append(label_file['# Feeding'][i])\n",
    "\n",
    "    print(len(a[0])/12, len(aa))\n",
    "\n",
    "\n",
    "c=[]\n",
    "for i in range(0,len(total_data[0]), 12):\n",
    "    a0=total_data[0][i:i+12]\n",
    "    b0=total_data[1][i:i+12]\n",
    "    c0=total_data[2][i:i+12]\n",
    "    a0_var=np.var(a0)\n",
    "    b0_var=np.var(b0)\n",
    "    c0_var=np.var(c0)\n",
    "    a0_deviation=median_absolute_deviation(a0)\n",
    "    b0_deviation=median_absolute_deviation(b0)\n",
    "    c0_deviation=median_absolute_deviation(c0)\n",
    "#     if(a0_var>10000):\n",
    "#         a0_var/=5\n",
    "#     if(b0_var>10000):\n",
    "#         b0_var/=5\n",
    "#     if(c0_var>10000):\n",
    "#         c0_var/=5\n",
    "#     if(a0_deviation<500):\n",
    "#         a0_deviation*=5\n",
    "#     if(b0_deviation<500):\n",
    "#         b0_deviation*=5\n",
    "#     if(a0_deviation<500):\n",
    "#         b0_deviation*=5\n",
    "    \n",
    "    a0_1=[ np.mean(a0), np.median(a0), a0_var, np.max(a0),np.min(a0), np.percentile(a0,25), np.percentile(a0,50), np.percentile(a0,75),a0_deviation]\n",
    "    b0_1=[ np.mean(b0), np.median(b0),  b0_var, np.max(b0), np.min(b0), np.percentile(b0,25), np.percentile(a0,50), np.percentile(b0,75),a0_deviation]\n",
    "    c0_1=[ np.mean(c0), np.median(c0),  c0_var, np.max(c0), np.min(c0), np.percentile(c0,25), np.percentile(a0,50), np.percentile(c0,75),a0_deviation]\n",
    "    \n",
    "    a0_feature=total_data[0][i:i+12]\n",
    "    b0_feature=total_data[1][i:i+12]\n",
    "    c0_feature=total_data[2][i:i+12]\n",
    "    \n",
    "    a0_feature=np.concatenate((a0_feature,a0_1))\n",
    "    b0_feature=np.concatenate((b0_feature,b0_1))\n",
    "    c0_feature=np.concatenate((c0_feature,c0_1))\n",
    "    \n",
    "    #  c.append(np.array([total_data[0][i:i+12], total_data[1][i:i+12], total_data[2][i:i+12]]))\n",
    "    c.append(np.array([a0_feature, b0_feature, c0_feature]))\n",
    "d=[]\n",
    "# c=d[0].reshape(1,60) (12+8)*3\n",
    "for i in range(len(c)):\n",
    "    d.append(c[i].reshape(1, 63))\n",
    "    d[i]=d[i][0]\n",
    "\n",
    "dataset=d\n",
    "\n",
    "\n",
    "print(len(dataset), len(total_label))      \n",
    "        \n",
    "\n",
    "# a=[];\n",
    "# acc_x=np.zeros(N)\n",
    "# acc_y=np.zeros(N)\n",
    "# acc_z=np.zeros(N)\n",
    "# for i in range(N):\n",
    "#     acc_x[i]=int(acc_data_x[i])\n",
    "#     acc_y[i]=int(acc_data_y[i])\n",
    "#     acc_z[i]=int(acc_data_z[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1884.        ,  1950.        ,  1898.        ,  1945.        ,\n",
       "        1954.        ,  2020.        ,  1942.        ,  2004.        ,\n",
       "        1904.        ,  1984.        ,  1911.        ,  1943.        ,\n",
       "        1944.91662598,  1944.        ,  1626.07653809,  2020.        ,\n",
       "        1884.        ,  1909.25      ,  1944.        ,  1961.5       ,\n",
       "          36.5       ,  2163.        ,  2280.        ,  2321.        ,\n",
       "        2300.        ,  2286.        ,  2427.        ,  2260.        ,\n",
       "        2261.        ,  2330.        ,  2220.        ,  2214.        ,\n",
       "        2197.        ,  2271.58325195,  2270.5       ,  4555.90966797,\n",
       "        2427.        ,  2163.        ,  2218.5       ,  1944.        ,\n",
       "        2305.25      ,    36.5       ,  2320.        ,  2287.        ,\n",
       "        2324.        ,  2242.        ,  2260.        ,  2272.        ,\n",
       "        2216.        ,  2268.        ,  2339.        ,  2330.        ,\n",
       "        2280.        ,  2248.        ,  2282.16674805,  2276.        ,\n",
       "        1390.13879395,  2339.        ,  2216.        ,  2257.        ,\n",
       "        1944.        ,  2321.        ,    36.5       ])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_dataset=[]\n",
    "new_labels_multiple=[]\n",
    "for i in range(len(dataset)):\n",
    "    if(total_label[i]==5):\n",
    "        continue\n",
    "    new_dataset.append(dataset[i])\n",
    "    new_labels_multiple.append(total_label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1785"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_dataset)\n",
    "len(new_labels_multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.55865922,  0.55865922,  0.55865922,  0.55865922,  0.55865922,\n",
       "        0.55865922,  0.55865922,  0.56179775,  0.55932203,  0.55932203])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='rbf', C=1)\n",
    "scores = cross_val_score(clf, new_dataset, new_labels_multiple, cv=10)\n",
    "\n",
    "scores\n",
    "# clf = svm.SVC(kernel='Linear', C=1).fit(X_train, y_train)\n",
    "# clf.score(X_test, y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.56 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1944.91662598,  1944.        ,  2020.        ,  1884.        ,\n",
       "        1626.07653809,  1909.25      ,  1961.5       ,    36.5       ,\n",
       "        2271.58325195,  2270.5       ,  2427.        ,  2163.        ,\n",
       "        4555.90966797,  2218.5       ,  2305.25      ,    50.5       ,\n",
       "        2282.16674805,  2276.        ,  2339.        ,  2216.        ,\n",
       "        1390.13879395,  2257.        ,  2321.        ,    31.        ])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2277.5416870117188"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(dataset[0],75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from astropy.stats import median_absolute_deviation\n",
    "np.var([1,2,3, 4, 5])\n",
    "np.max([1,2,3,4,5])\n",
    "a=[1,1,1,1,1]\n",
    "\n",
    "b=median_absolute_deviation(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1970.,  1996.,  1945.,  1964.,  1962.,  1932.,  1909.,  1988.,\n",
       "        1924.,  1974.,  1982.,  1972.,  2192.,  2196.,  2198.,  2176.,\n",
       "        2181.,  2192.,  2168.,  2140.,  2202.,  2129.,  2260.,  2165.,\n",
       "        2444.,  2341.,  2308.,  2336.,  2320.,  2362.,  2338.,  2339.,\n",
       "        2357.,  2355.,  2352.,  2339.], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=new_dataset[100]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2164.11 2186.5 2444.0 1909.0 26360.7 1980.0 2336.5 153.5\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(a), np.median(a), np.max(a), np.min(a), np.var(a), np.percentile(a,25), np.percentile(a,75), \\\n",
    "median_absolute_deviation(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25.00000000+0.j        ,   3.36396103-7.94974747j,\n",
       "       -10.00000000+1.j        ,  -9.36396103-1.94974747j,\n",
       "        -9.00000000+0.j        ,  -9.36396103+1.94974747j,\n",
       "       -10.00000000-1.j        ,   3.36396103+7.94974747j])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal = np.array([-2, 8, 6, 4, 1, 0, 3, 5], dtype=float)\n",
    "fourier = np.fft.fft(signal)\n",
    "fourier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 0\n"
     ]
    }
   ],
   "source": [
    "attribute_file='0808_00001_2449_Lau'\n",
    "#0808_00000_2457_Lau\n",
    "#0808_00001_2449_Lau 0.81\n",
    "#0808_00002_2454_Lau.csv 0.60\n",
    "\n",
    "total_label=[]\n",
    "#dataFile=full_path2[iteration]\n",
    "#attribute_file=filename6[0][0:len(filename6[0])-4]\n",
    "dataFile=folder2+attribute_file+'.mat'\n",
    "#print(dataFile)\n",
    "#dataFile = './output/0808_00000_2457_Lau.mat'\n",
    "data = scio.loadmat(dataFile)\n",
    "acc_data_x=data['acc_data_x'][0]\n",
    "acc_data_y=data['acc_data_y'][0]\n",
    "acc_data_z=data['acc_data_z'][0]\n",
    "\n",
    "NaN_number=[]\n",
    "for j in range(len(acc_data_x)):\n",
    "    if(math.isnan(acc_data_x[j]) or math.isnan(acc_data_y[j]) or math.isnan(acc_data_z[j])\\\n",
    "      or math.isinf(acc_data_x[j]) or math.isinf(acc_data_y[j]) or math.isinf(acc_data_z[j])):\n",
    "        NaN_number.append(math.floor(j/12))\n",
    "#print(NaN_number)\n",
    "total_data=[acc_data_x, acc_data_y, acc_data_z]\n",
    "\n",
    "c=[]\n",
    "for i in range(0,len(total_data[0]), 12):\n",
    "    a0=total_data[0][i:i+12]\n",
    "    b0=total_data[1][i:i+12]\n",
    "    c0=total_data[2][i:i+12]\n",
    "    a0_var=np.var(a0)\n",
    "    b0_var=np.var(b0)\n",
    "    c0_var=np.var(c0)\n",
    "    a0_deviation=median_absolute_deviation(a0)\n",
    "    b0_deviation=median_absolute_deviation(b0)\n",
    "    c0_deviation=median_absolute_deviation(c0)\n",
    "#     if(a0_var>10000):\n",
    "#         a0_var/=5\n",
    "#     if(b0_var>10000):\n",
    "#         b0_var/=5\n",
    "#     if(c0_var>10000):\n",
    "#         c0_var/=5\n",
    "#     if(a0_deviation<500):\n",
    "#         a0_deviation*=5\n",
    "#     if(b0_deviation<500):\n",
    "#         b0_deviation*=5\n",
    "#     if(a0_deviation<500):\n",
    "#         b0_deviation*=5\n",
    "    \n",
    "    a0_1=[ np.mean(a0), np.median(a0), a0_var, np.max(a0),np.min(a0), np.percentile(a0,25), np.percentile(a0,50), np.percentile(a0,75),a0_deviation]\n",
    "    b0_1=[ np.mean(b0), np.median(b0),  b0_var, np.max(b0), np.min(b0), np.percentile(b0,25), np.percentile(a0,50), np.percentile(b0,75),a0_deviation]\n",
    "    c0_1=[ np.mean(c0), np.median(c0),  c0_var, np.max(c0), np.min(c0), np.percentile(c0,25), np.percentile(a0,50), np.percentile(c0,75),a0_deviation]\n",
    "    \n",
    "    a0_feature=total_data[0][i:i+12]\n",
    "    b0_feature=total_data[1][i:i+12]\n",
    "    c0_feature=total_data[2][i:i+12]\n",
    "    \n",
    "    a0_feature=np.concatenate((a0_feature,a0_1))\n",
    "    b0_feature=np.concatenate((b0_feature,b0_1))\n",
    "    c0_feature=np.concatenate((c0_feature,c0_1))\n",
    "    \n",
    "    #  c.append(np.array([total_data[0][i:i+12], total_data[1][i:i+12], total_data[2][i:i+12]]))\n",
    "    c.append(np.array([a0_feature, b0_feature, c0_feature]))\n",
    "d=[]\n",
    "# c=d[0].reshape(1,60) (12+8)*3\n",
    "for i in range(len(c)):\n",
    "    d.append(c[i].reshape(1, 63))\n",
    "    d[i]=d[i][0]\n",
    "\n",
    "dataset=d\n",
    "\n",
    "\n",
    "print(len(dataset), len(total_label))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2130.        ,  2021.        ,  2142.        ,  2165.        ,\n",
       "        2113.        ,  2123.        ,  2077.        ,  2070.        ,\n",
       "        2049.        ,  2038.        ,  2048.        ,  2088.        ,\n",
       "        2088.66674805,  2082.5       ,  1917.38903809,  2165.        ,\n",
       "        2021.        ,  2048.75      ,  2082.5       ,  2124.75      ,\n",
       "          37.5       ,  2260.        ,  2241.        ,  2259.        ,\n",
       "        2251.        ,  2289.        ,  2277.        ,  2332.        ,\n",
       "        2301.        ,  2325.        ,  2331.        ,  2286.        ,\n",
       "        2280.        ,  2286.        ,  2283.        ,   889.        ,\n",
       "        2332.        ,  2241.        ,  2259.75      ,  2082.5       ,\n",
       "        2307.        ,    37.5       ,  1601.        ,  1498.        ,\n",
       "        1613.        ,  1641.        ,  1636.        ,  1582.        ,\n",
       "        1612.        ,  1667.        ,  1656.        ,  1689.        ,\n",
       "        1653.        ,  1581.        ,  1619.08337402,  1624.5       ,\n",
       "        2363.74316406,  1689.        ,  1498.        ,  1596.25      ,\n",
       "        2082.5       ,  1653.75      ,    37.5       ])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_label=[]\n",
    "\n",
    "label_file=pd.read_csv(folder6+attribute_file.lower()+'.csv')\n",
    "for i in range(len(label_file['# Feeding'])):\n",
    "    if(i in NaN_number): \n",
    "        total_label.append(5)\n",
    "        continue\n",
    "    total_label.append(label_file['# Feeding'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_dataset=[]\n",
    "new_labels_multiple=[]\n",
    "for i in range(len(dataset)):\n",
    "    if(total_label[i]==5):\n",
    "        continue\n",
    "    new_dataset.append(dataset[i])\n",
    "    new_labels_multiple.append(total_label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_dataset)\n",
    "# dd=0\n",
    "# for i in new_labels_multiple:\n",
    "#     if(i==1):\n",
    "#         dd+=1\n",
    "# print(dd/555)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5625    ,  0.57142857,  0.57142857,  0.57142857,  0.57142857,\n",
       "        0.57142857,  0.57142857,  0.57142857,  0.57142857,  0.57142857])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='rbf', C=1)\n",
    "scores = cross_val_score(clf, new_dataset, new_labels_multiple, cv=10)\n",
    "\n",
    "scores\n",
    "# clf = svm.SVC(kernel='Linear', C=1).fit(X_train, y_train)\n",
    "# clf.score(X_test, y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.57 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Multiple_labels/\n"
     ]
    }
   ],
   "source": [
    "#0814_00003_2451_Lau.csv\n",
    "print(folder6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89221556886227549"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     new_dataset, new_labels_multiple, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='rbf', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.89221557,  0.94011976,  0.90419162,  0.95209581,  0.94011976,\n",
       "        0.91616766,  0.95808383,  0.91616766,  0.92814371,  0.92814371])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "#n_samples = iris.data.shape[0]\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "s=cross_val_score(clf,new_dataset, new_labels_multiple, cv=cv)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
